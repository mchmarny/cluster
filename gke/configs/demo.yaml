apiVersion: github.com/mchmarny/cluster/v1alpha1
kind: Cluster

deployment:
  id: d1  # used to prefix all resources (must be unique per tenancy)
  csp: GCP
  tenancy: "my-project-name"  # GCP project ID, not name
  location: us-east5
  destroy: false
  tags:
    owner: mchmarny
    env: dev

cluster:
  name: demo
  version: "1.33"
  releaseChannel: STABLE  # RAPID, REGULAR, STABLE, or null for static version
  
  # GKE-specific features
  features:
    workloadIdentity: true
    gcpFilestoreCsiDriver: true
    gcsFuseCsiDriver: true
    
  addons:  # GKE managed addons
    gcePersistentDiskCsiDriver: true
    
  controlPlane:
    cidr: 172.20.0.0/16  # services CIDR
    podCidr: 10.100.0.0/16  # pods CIDR
    authorizedNetworks:  # CIDRs allowed to access control plane (e.g. kubectl)
      - cidr: 1.2.3.4/27
        name: NYC-Office
      - cidr: 5.6.7.8/32
        name: LON-Office
  
  # Private cluster configuration
  private:
    enabled: true
    masterIpv4CidrBlock: 172.16.0.0/28  # Control plane VPC peering CIDR
    
  # Maintenance window
  maintenance:
    window:
      startTime: "03:00"  # UTC

security:
  binaryAuthorization:
    enabled: false
  secretsEncryption:
    enabled: true
    kmsKeyName: ""  # Auto-generated if empty

network:
  name: gke-network  # VPC name
  cidr: 10.0.0.0/16  # VPC CIDR
  
  subnets:
    # Primary subnet for nodes
    nodes:
      - name: system-subnet
        cidr: 10.0.0.0/22
        privateGoogleAccess: true
        
      - name: worker-subnet
        cidr: 10.0.128.0/17
        privateGoogleAccess: true
    
    # Secondary ranges for pods and services (per subnet)
    secondary:
      system-subnet:
        pods:
          rangeName: system-pods
          cidr: 10.100.0.0/17
        services:
          rangeName: system-services
          cidr: 172.20.0.0/22
          
      worker-subnet:
        pods:
          rangeName: worker-pods
          cidr: 10.100.128.0/17
        services:
          rangeName: worker-services
          cidr: 172.20.128.0/17
  
  # Cloud NAT configuration
  nat:
    enabled: true
    sourceSubnetIpRangesToNat: ALL_SUBNETWORKS_ALL_IP_RANGES
    minPortsPerVm: 64
    
  # Firewall rules
  firewallRules:
    - name: allow-internal
      direction: INGRESS
      priority: 1000
      sourceRanges:
        - 10.0.0.0/16
        - 10.100.0.0/16
      allowed:
        - protocol: tcp
        - protocol: udp
        - protocol: icmp
        
    - name: allow-healthcheck
      direction: INGRESS
      priority: 1000
      sourceRanges:
        - 35.191.0.0/16
        - 130.211.0.0/22
      allowed:
        - protocol: tcp

compute:
  nodePools:
    
    # System node pool (for cluster services)
    system:
      machineType: e2-standard-4
      imageType: COS_CONTAINERD  # COS_CONTAINERD, UBUNTU_CONTAINERD, etc.
      diskType: pd-standard
      diskSizeGb: 100
      
      autoscaling:
        enabled: true
        minNodes: 1
        maxNodes: 3
        locationPolicy: BALANCED  # BALANCED or ANY
        
      autoUpgrade: true
      autoRepair: true
      
      nodeConfig:
        preemptible: false
        spot: false
        
        tags:
          - gke-node
          - system-node
          
        labels:
          nodeGroup: system
          workload: system
          
        taints:
          - key: dedicated
            value: CriticalAddonsOnly
            effect: NO_SCHEDULE
          - key: dedicated
            value: CriticalAddonsOnly
            effect: NO_EXECUTE
            
        metadata:
          disable-legacy-endpoints: "true"
          
        oauthScopes:
          - https://www.googleapis.com/auth/cloud-platform
          
        shieldedInstanceConfig:
          enableSecureBoot: true
          enableIntegrityMonitoring: true
    
    # Worker node pools
    workers:
      - name: cpu-worker-1
        machineType: n2-standard-8
        imageType: COS_CONTAINERD
        diskType: pd-ssd
        diskSizeGb: 200
        
        autoscaling:
          enabled: true
          minNodes: 1
          maxNodes: 10
          
        autoUpgrade: true
        autoRepair: true
        
        nodeConfig:
          preemptible: false
          spot: false
          
          tags:
            - gke-node
            - worker-node
            - cpu-worker
            - amd64
            
          labels:
            nodeGroup: cpu-worker
            workload: general
            architecture: amd64
            
          taints:
            - key: dedicated
              value: worker-workload
              effect: NO_SCHEDULE
              
          oauthScopes:
            - https://www.googleapis.com/auth/cloud-platform
      
      - name: cpu-worker-2
        machineType: n2-standard-8
        imageType: COS_CONTAINERD
        diskType: pd-ssd
        diskSizeGb: 200
        
        autoscaling:
          enabled: true
          minNodes: 1
          maxNodes: 10
          
        autoUpgrade: true
        autoRepair: true
        
        nodeConfig:
          preemptible: false
          spot: false
          
          tags:
            - gke-node
            - worker-node
            - cpu-worker
            - arm64
            
          labels:
            nodeGroup: cpu-worker
            workload: general
            architecture: arm64
            
          taints:
            - key: dedicated
              value: worker-workload
              effect: NO_SCHEDULE
              
          oauthScopes:
            - https://www.googleapis.com/auth/cloud-platform

      # GPU Worker Pool Example
      # To enable GPU nodes:
      #   1. Check GPU availability: gcloud compute accelerator-types list --filter="zone:us-east5"
      #   2. Uncomment the section below and adjust GPU type/zones as needed
      
      - name: gpu-worker-3
        machineType: a3-megagpu-8g  # H100 GPU instance
        imageType: COS_CONTAINERD
        diskType: pd-ssd
        diskSizeGb: 500
        
        guestAccelerator:
          type: H100  # GPU type
          count: 1
          gpuDriverInstallation:
            gpuDriverVersion: DEFAULT
          gpuSharingConfig: null  # Optional GPU sharing
          
        autoscaling:
          enabled: true
          minNodes: 0
          maxNodes: 5
          
        autoUpgrade: true
        autoRepair: true
        
        nodeConfig:
          preemptible: false
          spot: false

          capacityReservations:
            - "projects/my-project-name/reservations/gsc-a3-megagpu-8g-res-1"
          
          tags:
            - gke-node
            - worker-node
            - gpu-worker
            
          labels:
            nodeGroup: gpu-worker
            workload: ml
            accelerator: nvidia-a100
            
          taints:
            - key: nvidia.com/gpu
              value: "true"
              effect: NO_SCHEDULE
            - key: dedicated
              value: gpu-workload
              effect: NO_SCHEDULE
              
          oauthScopes:
            - https://www.googleapis.com/auth/cloud-platform
            
          shieldedInstanceConfig:
            enableSecureBoot: true
            enableIntegrityMonitoring: true
